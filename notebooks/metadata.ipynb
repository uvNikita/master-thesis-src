{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import sqlite3\n",
    "import codecs\n",
    "import cPickle as pickle\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "from ntb.constants import *\n",
    "from ntb.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse nor -> eng translation from tags.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_to_sqlite(f, conn):\n",
    "    for nor, eng in parse_gen(f):\n",
    "        try:\n",
    "            conn.execute('INSERT INTO translation VALUES (?, ?)', (nor, eng))\n",
    "        except sqlite3.IntegrityError as e:\n",
    "            print e, ':', nor, '->', eng\n",
    "\n",
    "def parse_to_json(f, out):\n",
    "    json.dump(dict(parse_gen(f)), out)\n",
    "\n",
    "def parse_trans(f):\n",
    "    nor_synonims = []\n",
    "    curr_indent = 0\n",
    "    eng = None\n",
    "    result = {}\n",
    "    for raw_line in f:\n",
    "        line = raw_line.strip()\n",
    "        if not line or  line[0] in ('\"', '=', '/', ';', '$'):\n",
    "            continue\n",
    "        prev_indent = curr_indent\n",
    "        curr_indent = len(raw_line) - len(raw_line.lstrip())\n",
    "        if line[0].isalnum():\n",
    "            for nor in nor_synonims:\n",
    "                nor = subj_to_tag(nor)\n",
    "                if nor in result:\n",
    "                    continue\n",
    "                elif eng is None:\n",
    "                    raise ValueError(\"No translation for \", nor)\n",
    "                else:\n",
    "                    result[nor] = subj_to_tag(eng)\n",
    "            nor_synonims = [line]\n",
    "            eng = None\n",
    "        elif line[0] == '#':\n",
    "            nor_synonims.append(line[1:])\n",
    "        elif line[0] == u'£':\n",
    "            if curr_indent != prev_indent and nor_synonims:\n",
    "                print curr_indent, prev_indent, raw_line, line\n",
    "                raise ValueError(\"No translation for \", nor_synonims)\n",
    "            eng = line.lstrip(u';£')\n",
    "        elif line[0] == '*':\n",
    "            # connected\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError(\"Wrong line: {}\".format(line))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(os.path.join(BASE_DIR, 'tags.txt'), encoding='utf-8') as inp:\n",
    "    trans = parse_trans(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse tfo files to metadata.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BLACK_AND_WHITE_TAGS = {'svarthvitt', 'blackandwhite', 'monochrome', 'svartvit'}\n",
    "\n",
    "def subj_fixes(subj):\n",
    "    if subj == \"pc'er\":\n",
    "        return \"pc-er\"\n",
    "    subj = subj.replace(u'é', u'e')\n",
    "    subj = subj.replace(u'è', 'e')\n",
    "    subj = subj.rstrip(u'¨.*<>|')\n",
    "    subj = subj.lstrip(u'¨.*<>|')\n",
    "    return subj\n",
    "\n",
    "class Indicator(Enum):\n",
    "    newfile = \"R^\"\n",
    "    filename = \"1F^\"\n",
    "    subject = \"70F^\"\n",
    "#     persons = \"66F^\"\n",
    "#     caption = \"63F^\"\n",
    "    extra = \"47F^\"\n",
    "\n",
    "def read_tfo_field_gen(f):\n",
    "    while True:\n",
    "        entry = f.readline().strip()\n",
    "        if not entry or not entry[1:-1]:\n",
    "            return\n",
    "        else:\n",
    "            yield entry[1:-1].lower()\n",
    "\n",
    "def parse_tfo(f, folder):\n",
    "    images = {}\n",
    "    current_image = {}\n",
    "    skipped = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            print \"{}: saved {}, skipped (B/W) {}\".format(folder, len(images), skipped)\n",
    "            return images\n",
    "        try:\n",
    "            field = Indicator(line.strip())\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if field == Indicator.newfile:\n",
    "            if current_image:\n",
    "                if set(current_image.get('extra', [])).intersection(BLACK_AND_WHITE_TAGS):\n",
    "                    skipped += 1 # skipping black and white images\n",
    "                else:\n",
    "                    current_image.setdefault('tags', [])\n",
    "                    current_image['folder'] = folder\n",
    "                    del current_image['extra'] # don't need this field for now\n",
    "                    images[current_image['filename']] = current_image\n",
    "            current_image = {}\n",
    "        elif field == Indicator.filename:\n",
    "            filename = next(read_tfo_field_gen(f))\n",
    "            current_image['filename'] = filename\n",
    "        elif field == Indicator.subject:\n",
    "            current_image['tags'] = list(set(map(subj_to_tag, map(subj_fixes, read_tfo_field_gen(f)))))\n",
    "        else:\n",
    "            current_image[field.name] = list(set(read_tfo_field_gen(f)))\n",
    "\n",
    "def translate(trans, metadata):\n",
    "    for pic in metadata.itervalues():\n",
    "        pic['tags'] = filter(None, map(lambda t: trans.get(t, None), pic['tags']))\n",
    "\n",
    "def missing_translations_gen(trans, metadata):\n",
    "    for pic in metadata.itervalues():\n",
    "        for tag in pic['tags']:\n",
    "            if tag not in trans:\n",
    "                yield tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996_TO_2001: saved 81737, skipped (B/W) 29543\n",
      "2005_TO_2007: saved 142875, skipped (B/W) 12364\n",
      "2010_TO_2011: saved 123335, skipped (B/W) 41\n",
      "2013: saved 58305, skipped (B/W) 20\n",
      "2015: saved 74474, skipped (B/W) 50\n",
      "2002_TO_2004: saved 104066, skipped (B/W) 10351\n",
      "2008_TO_2009: saved 109684, skipped (B/W) 338\n",
      "2012: saved 71247, skipped (B/W) 33\n",
      "2014: saved 71912, skipped (B/W) 54\n",
      "2016_01_TO_10: saved 75799, skipped (B/W) 143\n",
      "Missing translations:  105\n"
     ]
    }
   ],
   "source": [
    "metadata = {}\n",
    "for folder in PICS_FOLDERS:\n",
    "    with codecs.open(os.path.join(BASE_DIR, 'metadata_tfo_files', folder + '.tfo'), encoding='iso8859') as f:\n",
    "        metadata.update(parse_tfo(f, folder))\n",
    "print \"Missing translations: \", len(list(missing_translations_gen(trans, metadata)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might need to create file and give write permissions for all befor running due to owner bug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translate(trans, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_DIR, 'metadata.pickle'), mode='w') as out:\n",
    "        pickle.dump(metadata, out, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse tags file to newick file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def children_to_str(children):\n",
    "    children_str = ','.join(children)\n",
    "    if children_str:\n",
    "        return '({})'.format(children_str)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def read_children(ls, ident=0, max_children=None):\n",
    "    children = []\n",
    "    while True:\n",
    "        if not ls:\n",
    "            return children_to_str(children)\n",
    "        line = ls.pop(0)\n",
    "        curr_ident = len(line) - len(line.lstrip(' '))\n",
    "        if curr_ident == ident:\n",
    "            child_name = subj_to_tag(line)\n",
    "            child = read_children(ls, ident + 2) + child_name\n",
    "            children.append(child)\n",
    "        elif curr_ident < ident:\n",
    "            ls.insert(0, line)\n",
    "            return children_to_str(children)\n",
    "        else:\n",
    "            print ident, children, line, curr_ident\n",
    "            raise ValueError(\"Wrong tree\")\n",
    "    return tree, None\n",
    "\n",
    "def read_tree(tree_str):\n",
    "    return read_children(tree_str.splitlines())[1:-1] + ';'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might need to create file and give write permissions for all befor running due to owner bug:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_DIR, 'tags.eng.txt')) as in_file:\n",
    "    tag_tree = read_tree(in_file.read())\n",
    "with open(os.path.join(BASE_DIR, 'tags.nw'), mode='w') as out_file:\n",
    "    out_file.write(tag_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
